{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3819cd5b",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8e6d1",
   "metadata": {},
   "source": [
    "Objective: Build and compare models for 3-gameweek forecasting while\n",
    "          addressing the 61% zero-point distribution problem.\n",
    "\n",
    "Model Architecture:\n",
    "1. Naive Regression (Baseline)\n",
    "2. Filtered Regression (Train only on playing time)\n",
    "3. Two-Stage Model (Classification + Regression)\n",
    "\n",
    "Mathematical Foundation:\n",
    "For zero-inflated data, the expected value decomposes as:\n",
    "\n",
    "E[Y] = P(Y > 0) Ã— E[Y | Y > 0]\n",
    "\n",
    "Two-stage approach models these components separately for better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b96684",
   "metadata": {},
   "source": [
    "## Setup & Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "584efa4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: (93666, 151)\n",
      "Memory: 144.2 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path.cwd().parent\n",
    "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "FEATURES_FILE = PROCESSED_DIR / \"fpl_features_engineered.csv\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(FEATURES_FILE)\n",
    "print(f\"Loaded: {df.shape}\")\n",
    "print(f\"Memory: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987cfbb7",
   "metadata": {},
   "source": [
    "## 1. Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ecc9b",
   "metadata": {},
   "source": [
    "Select features for modeling, excluding:\n",
    "- Target variables\n",
    "- IDs and metadata\n",
    "- High-cardinality strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f55cc395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Categories:\n",
      "  Rolling stats: 79\n",
      "  Lags: 10\n",
      "  Momentum: 7\n",
      "  Position: 6\n",
      "  Expected goals: 12\n",
      "  Base stats: 31\n",
      "  TOTAL: 136\n"
     ]
    }
   ],
   "source": [
    "# Encode position for analysis later\n",
    "df['position_encoded'] = df['position'].map({'GK': 0, 'DEF': 1, 'MID': 2, 'FWD': 3})\n",
    "\n",
    "# Exclude columns\n",
    "exclude_cols = [\n",
    "    'total_points',  # Target variable\n",
    "    'element', 'name', 'season', 'kickoff_time',  # IDs and metadata\n",
    "    'fixture', 'opponent_team', 'team',  # High cardinality\n",
    "    'match_score', 'opponent_team_name',  # Derived strings\n",
    "    'round', 'modified', 'xP', 'starts',  # Redundant/sparse\n",
    "    'points_above_4', 'points_above_6',  # Intermediate features\n",
    "]\n",
    "\n",
    "# Available feature columns\n",
    "feature_cols = [col for col in df.columns if col not in exclude_cols]\n",
    "\n",
    "# Separate by category for analysis\n",
    "rolling_features = [c for c in feature_cols if 'roll' in c]\n",
    "lag_features = [c for c in feature_cols if 'lag' in c]\n",
    "momentum_features = [c for c in feature_cols if any(x in c for x in ['momentum', 'streak', 'trend', 'acceleration'])]\n",
    "position_features = [c for c in feature_cols if 'position' in c or 'vs_' in c]\n",
    "xg_features = [c for c in feature_cols if 'expected' in c or 'xg' in c]\n",
    "base_features = [c for c in feature_cols if c not in rolling_features + lag_features + \n",
    "                 momentum_features + position_features + xg_features]\n",
    "\n",
    "print(\"Feature Categories:\")\n",
    "print(f\"  Rolling stats: {len(rolling_features)}\")\n",
    "print(f\"  Lags: {len(lag_features)}\")\n",
    "print(f\"  Momentum: {len(momentum_features)}\")\n",
    "print(f\"  Position: {len(position_features)}\")\n",
    "print(f\"  Expected goals: {len(xg_features)}\")\n",
    "print(f\"  Base stats: {len(base_features)}\")\n",
    "print(f\"  TOTAL: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf6f1d",
   "metadata": {},
   "source": [
    "## 2. Temporal Train-Validation-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b28a12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_temporal_split(df):\n",
    "    \"\"\"\n",
    "    Splits data maintaining strict temporal order.\n",
    "    \n",
    "    Train: 2021-22, 2022-23, 2023-24\n",
    "    Validation: 2024-25 (GW 20-21)\n",
    "    Test: 2025-26 (GW 1-15, current season)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple\n",
    "        (train_df, val_df, test_df)\n",
    "    \"\"\"\n",
    "    train_mask = df['season'].isin(['2021-22', '2022-23', '2023-24'])\n",
    "    val_mask = (df['season'] == '2024-25') & (df['GW'] >= 20)\n",
    "    test_mask = df['season'] == '2025-26'\n",
    "    \n",
    "    train_df = df[train_mask].copy()\n",
    "    val_df = df[val_mask].copy()\n",
    "    test_df = df[test_mask].copy()\n",
    "    \n",
    "    print(\"Temporal Split:\")\n",
    "    print(f\"  Train: {len(train_df):,} observations ({train_df['season'].unique()})\")\n",
    "    print(f\"  Val:   {len(val_df):,} observations ({val_df['season'].unique()})\")\n",
    "    print(f\"  Test:  {len(test_df):,} observations ({test_df['season'].unique()})\")\n",
    "    \n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e04101a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal Split:\n",
      "  Train: 68,398 observations (['2021-22' '2022-23' '2023-24'])\n",
      "  Val:   1,435 observations (['2024-25'])\n",
      "  Test:  11,090 observations (['2025-26'])\n",
      "\n",
      "Zero-Point Distribution:\n",
      "  Train: 60.5% zeros\n",
      "  Val: 61.0% zeros\n",
      "  Test: 60.5% zeros\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = create_temporal_split(df)\n",
    "\n",
    "# Analyze zero-inflation by split\n",
    "print(\"\\nZero-Point Distribution:\")\n",
    "for name, data in [('Train', train_df), ('Val', val_df), ('Test', test_df)]:\n",
    "    zero_pct = (data['total_points'] == 0).sum() / len(data) * 100\n",
    "    print(f\"  {name}: {zero_pct:.1f}% zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcca9a4f",
   "metadata": {},
   "source": [
    "## 3. Create Multi-Horizon Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75078417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_targets(df, horizons=[1, 2, 3]):\n",
    "    \"\"\"\n",
    "    Creates target variables for each forecast horizon.\n",
    "    Also creates binary classification target (will_play).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame with target_h1, target_h2, target_h3, will_play_h1, etc.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['element', 'season', 'GW']).copy()\n",
    "    \n",
    "    for h in horizons:\n",
    "        # Regression target (points)\n",
    "        df[f'target_h{h}'] = df.groupby('element')['total_points'].shift(-h)\n",
    "        \n",
    "        # Classification target (will play?)\n",
    "        df[f'will_play_h{h}'] = (df.groupby('element')['minutes'].shift(-h) > 0).astype(int)\n",
    "    \n",
    "    # Remove rows without targets (last 3 GWs per player)\n",
    "    df = df.dropna(subset=[f'target_h{h}' for h in horizons])\n",
    "    \n",
    "    print(f\"Created targets for horizons: {horizons}\")\n",
    "    print(f\"Final observations: {len(df):,}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e487d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created targets for horizons: [1, 2, 3]\n",
      "Final observations: 65,911\n",
      "Created targets for horizons: [1, 2, 3]\n",
      "Final observations: 0\n",
      "Created targets for horizons: [1, 2, 3]\n",
      "Final observations: 8,818\n"
     ]
    }
   ],
   "source": [
    "train_df = create_targets(train_df)\n",
    "val_df = create_targets(val_df)\n",
    "test_df = create_targets(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f1636",
   "metadata": {},
   "source": [
    "## 4. Prepare Feature Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbd1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Prepares feature matrix with missing value handling.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Feature matrix\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    # Fill missing values\n",
    "    # Strategy: For tree-based models, explicit NaN handling is better than imputation\n",
    "    # LightGBM can handle NaN natively, but we'll fill for compatibility\n",
    "    \n",
    "    # Fill numeric columns with median\n",
    "    numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "    \n",
    "    # Encode categorical (position, was_home)\n",
    "    if 'position' in X.columns:\n",
    "        X['position'] = X['position'].map({'GK': 0, 'DEF': 1, 'MID': 2, 'FWD': 3})\n",
    "    \n",
    "    if 'was_home' in X.columns:\n",
    "        X['was_home'] = X['was_home'].astype(int)\n",
    "    \n",
    "    return X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac74d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature matrices\n",
    "X_train = prepare_features(train_df, feature_cols)\n",
    "X_val = prepare_features(val_df, feature_cols)\n",
    "X_test = prepare_features(test_df, feature_cols)\n",
    "\n",
    "print(\"Feature matrix shapes:\")\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Val:   {X_val.shape}\")\n",
    "print(f\"  Test:  {X_test.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
