{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Model Laboratory: XGBoost Walk-Forward Validation\n",
    "\n",
    "**Objective:** Train and validate a Gradient Boosting Regressor (XGBoost) using a strict temporal split (Walk-Forward Validation).\n",
    "\n",
    "**Methodology:**\n",
    "1. **Training Window:** Expanding window (Train on Season $1..N$).\n",
    "2. **Testing Window:** Next chronological season (Test on Season $N+1$).\n",
    "3. **Metric:** Mean Absolute Error (MAE) - Optimizing for point accuracy.\n",
    "4. **Forensics:** Analyze Feature Importance and Residual Distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Robust Path Handling\n",
    "current_path = Path.cwd()\n",
    "if 'notebooks' in str(current_path).lower():\n",
    "    BASE_DIR = current_path.parent\n",
    "else:\n",
    "    BASE_DIR = current_path\n",
    "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load the Feature Matrix\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"Loading Feature Matrix...\")\n",
    "try:\n",
    "    df = pd.read_csv(PROCESSED_DIR / \"fpl_features_production.csv\")\n",
    "    print(f\"Loaded {len(df):,} rows.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"CRITICAL: Production features not found. Run Notebook 02 first.\")\n",
    "    # Stop execution if data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pre-Processing for Model\n",
    "# ------------------------------------------------------------------------------\n",
    "# Drop metadata that model can't use (names, teams, dates)\n",
    "# Keep 'season', 'GW', 'element' for splitting logic\n",
    "metadata_cols = ['name', 'kickoff_time', 'position', 'opponent_team_name']\n",
    "model_df = df.drop(columns=[c for c in metadata_cols if c in df.columns])\n",
    "\n",
    "print(f\"Model Ready Columns: {model_df.shape[1]}\")\n",
    "print(f\"Features included: {list(model_df.columns[:5])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "walk_forward",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Walk-Forward Validation (The Gold Standard)\n",
    "# ------------------------------------------------------------------------------\n",
    "# We train on Season N, Test on Season N+1.\n",
    "# This mimics the real-world scenario of predicting the \"unknown future\".\n",
    "\n",
    "seasons = sorted(df['season'].unique())\n",
    "print(f\"Seasons available: {seasons}\")\n",
    "\n",
    "results = []\n",
    "feature_importance_list = []\n",
    "\n",
    "print(\"\\n--- STARTING WALK-FORWARD VALIDATION ---\")\n",
    "\n",
    "for i, test_season in enumerate(seasons[1:]): # Start from 2nd season\n",
    "    train_seasons = seasons[:i+1]\n",
    "    \n",
    "    print(f\"\\nRound {i+1}: Train on {train_seasons} -> Test on {test_season}\")\n",
    "    \n",
    "    # Split Data\n",
    "    X_train = model_df[model_df['season'].isin(train_seasons)].drop(columns=['target_points_next_3', 'season', 'GW', 'element'])\n",
    "    y_train = model_df[model_df['season'].isin(train_seasons)]['target_points_next_3']\n",
    "    \n",
    "    X_test = model_df[model_df['season'] == test_season].drop(columns=['target_points_next_3', 'season', 'GW', 'element'])\n",
    "    y_test = model_df[model_df['season'] == test_season]['target_points_next_3']\n",
    "    \n",
    "    # Validation: Ensure we strictly separate time\n",
    "    print(f\"   Train Size: {len(X_train):,} | Test Size: {len(X_test):,}\")\n",
    "    \n",
    "    # Train XGBoost\n",
    "    model = xgb.XGBRegressor(\n",
    "        objective='reg:absoluteerror', # Minimize MAE\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        early_stopping_rounds=50,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Use last 20% of training data as validation set for early stopping\n",
    "    eval_set = [(X_train, y_train), (X_test, y_test)]\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=eval_set,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    print(f\"   MAE: {mae:.3f} | RMSE: {rmse:.3f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'test_season': test_season,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse\n",
    "    })\n",
    "    \n",
    "    # Store Feature Importance\n",
    "    fi = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': model.feature_importances_,\n",
    "        'season_fold': test_season\n",
    "    })\n",
    "    feature_importance_list.append(fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results_summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Results Aggregation\n",
    "# ------------------------------------------------------------------------------\n",
    "print(\"\\n--- VALIDATION SUMMARY ---\")\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "print(f\"\\nAverage MAE across seasons: {results_df['MAE'].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Global Feature Importance Analysis\n",
    "# ------------------------------------------------------------------------------\n",
    "all_fi = pd.concat(feature_importance_list)\n",
    "avg_fi = all_fi.groupby('feature')['importance'].mean().sort_values(ascending=False).head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "avg_fi.plot(kind='barh', color='#2c3e50')\n",
    "plt.title(\"Global Feature Importance (Averaged across folds)\")\n",
    "plt.xlabel(\"Gain\")\n",
    "plt.gca().invert_yaxis() # Top feature at top\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "error_analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Error Analysis: Where did we fail?\n",
    "# ------------------------------------------------------------------------------\n",
    "# Let's look at the residuals for the last fold\n",
    "residuals = y_test - preds\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, bins=50, kde=True, color='purple')\n",
    "plt.title(f\"Residual Distribution ({test_season})\")\n",
    "plt.xlabel(\"Actual - Predicted (Positive = Underprediction)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"NOTE: Model Lab Complete. Next step: Hyperparameter Tuning or Deployment.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
