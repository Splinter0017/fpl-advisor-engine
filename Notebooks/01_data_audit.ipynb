{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51b66355",
   "metadata": {},
   "source": [
    "# Fantasy Premier League Data Audit Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8de391",
   "metadata": {},
   "source": [
    "This notebook performs comprehensive data quality assessment across all seasons,\n",
    "validating schema consistency, identifying missing values, and examining temporal\n",
    "coverage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9186057d",
   "metadata": {},
   "source": [
    "## CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b2fe02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Directory: c:\\Users\\kadmi\\Workspace\\02_Projects\\fpl-advisor-engine\n",
      "Raw Data Directory: c:\\Users\\kadmi\\Workspace\\02_Projects\\fpl-advisor-engine\\data\\raw\n",
      "Processed Data Directory: c:\\Users\\kadmi\\Workspace\\02_Projects\\fpl-advisor-engine\\data\\processed\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path.cwd().parent if 'Notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "RAW_DIR = BASE_DIR / \"data\" / \"raw\"\n",
    "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "HISTORICAL_SEASONS = [\"2021-22\", \"2022-23\", \"2023-24\", \"2024-25\"]\n",
    "CURRENT_SEASON = \"2025-26\"\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Raw Data Directory: {RAW_DIR}\")\n",
    "print(f\"Processed Data Directory: {PROCESSED_DIR}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb33e9",
   "metadata": {},
   "source": [
    "## SECTION 1: FILE INVENTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90dbdbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-22: COMPLETE\n",
      "2022-23: COMPLETE\n",
      "2023-24: COMPLETE\n",
      "2024-25: COMPLETE\n",
      "2025-26: COMPLETE\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "available_files = {}\n",
    "\n",
    "for season in HISTORICAL_SEASONS + [CURRENT_SEASON]:\n",
    "    merged_file = RAW_DIR / f\"{season}_merged_gw.csv\"\n",
    "    teams_file = RAW_DIR / f\"{season}_teams.csv\"\n",
    "    \n",
    "    files_found = {\n",
    "        'merged_gw': merged_file.exists(),\n",
    "        'teams': teams_file.exists()\n",
    "    }\n",
    "    \n",
    "    available_files[season] = files_found\n",
    "    \n",
    "    status = \"COMPLETE\" if all(files_found.values()) else \"INCOMPLETE\"\n",
    "    print(f\"{season}: {status}\")\n",
    "    if not files_found['merged_gw']:\n",
    "        print(f\"  Missing: {season}_merged_gw.csv\")\n",
    "    if not files_found['teams']:\n",
    "        print(f\"  Missing: {season}_teams.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14ecc1b7",
   "metadata": {},
   "source": [
    "## SECTION 2: SCHEMA ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea3cf5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-22: 37 columns detected\n",
      "2022-23: 42 columns detected\n",
      "2023-24: 42 columns detected\n",
      "2024-25: 43 columns detected\n",
      "2025-26: 43 columns detected\n",
      "\n",
      "Common columns across all seasons: 33\n",
      "Total unique columns across all seasons: 47\n",
      "\n",
      "Inconsistent columns (not present in all seasons):\n",
      "  - GW: present in ['2021-22', '2022-23', '2023-24', '2024-25']\n",
      "  - clearances_blocks_interceptions: present in ['2025-26']\n",
      "  - defensive_contribution: present in ['2025-26']\n",
      "  - expected_assists: present in ['2022-23', '2023-24', '2024-25', '2025-26']\n",
      "  - expected_goal_involvements: present in ['2022-23', '2023-24', '2024-25', '2025-26']\n",
      "  - expected_goals: present in ['2022-23', '2023-24', '2024-25', '2025-26']\n",
      "  - expected_goals_conceded: present in ['2022-23', '2023-24', '2024-25', '2025-26']\n",
      "  - modified: present in ['2024-25', '2025-26']\n",
      "  - position: present in ['2021-22', '2022-23', '2023-24', '2024-25']\n",
      "  - recoveries: present in ['2025-26']\n",
      "  - starts: present in ['2022-23', '2023-24', '2024-25', '2025-26']\n",
      "  - tackles: present in ['2025-26']\n",
      "  - team: present in ['2021-22', '2022-23', '2023-24', '2024-25']\n",
      "  - xP: present in ['2021-22', '2022-23', '2023-24', '2024-25']\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema_info = {}\n",
    "\n",
    "for season in HISTORICAL_SEASONS + [CURRENT_SEASON]:\n",
    "    merged_file = RAW_DIR / f\"{season}_merged_gw.csv\"\n",
    "    \n",
    "    if not merged_file.exists():\n",
    "        print(f\"{season}: File not found, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(merged_file, nrows=5)\n",
    "        schema_info[season] = {\n",
    "            'columns': set(df.columns),\n",
    "            'n_columns': len(df.columns),\n",
    "            'dtypes': df.dtypes.to_dict()\n",
    "        }\n",
    "        print(f\"{season}: {len(df.columns)} columns detected\")\n",
    "    except Exception as e:\n",
    "        print(f\"{season}: Error reading file - {str(e)}\")\n",
    "        schema_info[season] = None\n",
    "# Identify common columns across all seasons\n",
    "if schema_info:\n",
    "    all_columns = [info['columns'] for info in schema_info.values() if info is not None]\n",
    "    \n",
    "    if all_columns:\n",
    "        common_columns = set.intersection(*all_columns)\n",
    "        all_unique_columns = set.union(*all_columns)\n",
    "        \n",
    "        print(f\"\\nCommon columns across all seasons: {len(common_columns)}\")\n",
    "        print(f\"Total unique columns across all seasons: {len(all_unique_columns)}\")\n",
    "        \n",
    "        # Identify columns that exist in some seasons but not others\n",
    "        inconsistent_columns = all_unique_columns - common_columns\n",
    "        if inconsistent_columns:\n",
    "            print(\"\\nInconsistent columns (not present in all seasons):\")\n",
    "            for col in sorted(inconsistent_columns):\n",
    "                seasons_with_col = [s for s, info in schema_info.items() \n",
    "                                   if info and col in info['columns']]\n",
    "                print(f\"  - {col}: present in {seasons_with_col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af153f38",
   "metadata": {},
   "source": [
    "## SECTION 3: DETAILED DATA PROFILING (First season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7af12a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 2021-22 as reference season...\n",
      "\n",
      "Dataset Shape: 25,447 rows × 37 columns\n",
      "Memory Usage: 13.32 MB\n",
      "\n",
      "Column Inventory:\n",
      "--------------------------------------------------------------------------------\n",
      " 1. name                      | object     | Missing:      0 ( 0.00%) | Unique:    735\n",
      " 2. position                  | object     | Missing:      0 ( 0.00%) | Unique:      5\n",
      " 3. team                      | object     | Missing:      0 ( 0.00%) | Unique:     20\n",
      " 4. xP                        | float64    | Missing:      0 ( 0.00%) | Unique:    174\n",
      " 5. assists                   | int64      | Missing:      0 ( 0.00%) | Unique:      5\n",
      " 6. bonus                     | int64      | Missing:      0 ( 0.00%) | Unique:      4\n",
      " 7. bps                       | int64      | Missing:      0 ( 0.00%) | Unique:     87\n",
      " 8. clean_sheets              | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      " 9. creativity                | float64    | Missing:      0 ( 0.00%) | Unique:    634\n",
      "10. element                   | int64      | Missing:      0 ( 0.00%) | Unique:    737\n",
      "11. fixture                   | int64      | Missing:      0 ( 0.00%) | Unique:    380\n",
      "12. goals_conceded            | int64      | Missing:      0 ( 0.00%) | Unique:      8\n",
      "13. goals_scored              | int64      | Missing:      0 ( 0.00%) | Unique:      5\n",
      "14. ict_index                 | float64    | Missing:      0 ( 0.00%) | Unique:    222\n",
      "15. influence                 | float64    | Missing:      0 ( 0.00%) | Unique:    405\n",
      "16. kickoff_time              | object     | Missing:      0 ( 0.00%) | Unique:    229\n",
      "17. minutes                   | int64      | Missing:      0 ( 0.00%) | Unique:     90\n",
      "18. opponent_team             | int64      | Missing:      0 ( 0.00%) | Unique:     20\n",
      "19. own_goals                 | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      "20. penalties_missed          | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      "21. penalties_saved           | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      "22. red_cards                 | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      "23. round                     | int64      | Missing:      0 ( 0.00%) | Unique:     38\n",
      "24. saves                     | int64      | Missing:      0 ( 0.00%) | Unique:     11\n",
      "25. selected                  | int64      | Missing:      0 ( 0.00%) | Unique:  19236\n",
      "26. team_a_score              | int64      | Missing:      0 ( 0.00%) | Unique:      7\n",
      "27. team_h_score              | int64      | Missing:      0 ( 0.00%) | Unique:      8\n",
      "28. threat                    | float64    | Missing:      0 ( 0.00%) | Unique:    126\n",
      "29. total_points              | int64      | Missing:      0 ( 0.00%) | Unique:     27\n",
      "30. transfers_balance         | int64      | Missing:      0 ( 0.00%) | Unique:  10671\n",
      "31. transfers_in              | int64      | Missing:      0 ( 0.00%) | Unique:   8722\n",
      "32. transfers_out             | int64      | Missing:      0 ( 0.00%) | Unique:   9935\n",
      "33. value                     | int64      | Missing:      0 ( 0.00%) | Unique:     96\n",
      "34. was_home                  | bool       | Missing:      0 ( 0.00%) | Unique:      2\n",
      "35. yellow_cards              | int64      | Missing:      0 ( 0.00%) | Unique:      2\n",
      "36. GW                        | int64      | Missing:      0 ( 0.00%) | Unique:     38\n",
      "37. season                    | object     | Missing:      0 ( 0.00%) | Unique:      1\n",
      "\n",
      "Target Variable Statistics (total_points):\n",
      "--------------------------------------------------------------------------------\n",
      "count    25447.000000\n",
      "mean         1.234487\n",
      "std          2.451813\n",
      "min         -4.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          2.000000\n",
      "max         24.000000\n",
      "Name: total_points, dtype: float64\n",
      "\n",
      "Zero-point matches: 15,471 (60.8%)\n",
      "\n",
      "Gameweek Coverage:\n",
      "--------------------------------------------------------------------------------\n",
      "Gameweeks present: 1 to 38\n",
      "Total gameweeks: 38\n",
      "\n",
      "Players per gameweek (sample):\n",
      "GW\n",
      "1     554\n",
      "2     566\n",
      "3     577\n",
      "4     599\n",
      "5     606\n",
      "6     611\n",
      "7     613\n",
      "8     617\n",
      "9     618\n",
      "10    623\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Position Distribution:\n",
      "--------------------------------------------------------------------------------\n",
      "position\n",
      "MID    10519\n",
      "DEF     8620\n",
      "FWD     3398\n",
      "GK      2809\n",
      "GKP      101\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Key Performance Metrics - Sample Statistics:\n",
      "--------------------------------------------------------------------------------\n",
      "                count       mean        std  min    max  missing  missing_pct\n",
      "total_points  25447.0   1.234487   2.451813 -4.0   24.0        0          0.0\n",
      "minutes       25447.0  29.452116  39.847840  0.0   90.0        0          0.0\n",
      "goals_scored  25447.0   0.040751   0.219746  0.0    4.0        0          0.0\n",
      "assists       25447.0   0.036507   0.204397  0.0    4.0        0          0.0\n",
      "clean_sheets  25447.0   0.094825   0.292978  0.0    1.0        0          0.0\n",
      "ict_index     25447.0   1.546949   2.929714  0.0   31.5        0          0.0\n",
      "influence     25447.0   6.345998  12.256550  0.0  163.4        0          0.0\n",
      "creativity    25447.0   4.207156  10.067910  0.0  136.2        0          0.0\n",
      "threat        25447.0   4.925453  13.049717  0.0  161.0        0          0.0\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load first available season for detailed inspection\n",
    "first_season = None\n",
    "for season in HISTORICAL_SEASONS:\n",
    "    merged_file = RAW_DIR / f\"{season}_merged_gw.csv\"\n",
    "    if merged_file.exists():\n",
    "        first_season = season\n",
    "        break\n",
    "\n",
    "if first_season:\n",
    "    print(f\"Analyzing {first_season} as reference season...\\n\")\n",
    "    \n",
    "    df_sample = pd.read_csv(RAW_DIR / f\"{first_season}_merged_gw.csv\")\n",
    "    \n",
    "    print(f\"Dataset Shape: {df_sample.shape[0]:,} rows × {df_sample.shape[1]} columns\")\n",
    "    print(f\"Memory Usage: {df_sample.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    print(\"\\nColumn Inventory:\")\n",
    "    print(\"-\" * 80)\n",
    "    for i, col in enumerate(df_sample.columns, 1):\n",
    "        dtype = df_sample[col].dtype\n",
    "        n_missing = df_sample[col].isna().sum()\n",
    "        pct_missing = (n_missing / len(df_sample)) * 100\n",
    "        n_unique = df_sample[col].nunique()\n",
    "        \n",
    "        print(f\"{i:2d}. {col:25s} | {str(dtype):10s} | \"\n",
    "              f\"Missing: {n_missing:6d} ({pct_missing:5.2f}%) | \"\n",
    "              f\"Unique: {n_unique:6d}\")\n",
    "    \n",
    "    print(\"\\nTarget Variable Statistics (total_points):\")\n",
    "    print(\"-\" * 80)\n",
    "    if 'total_points' in df_sample.columns:\n",
    "        points_stats = df_sample['total_points'].describe()\n",
    "        print(points_stats)\n",
    "        \n",
    "        print(f\"\\nZero-point matches: {(df_sample['total_points'] == 0).sum():,} \"\n",
    "              f\"({(df_sample['total_points'] == 0).sum() / len(df_sample) * 100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nGameweek Coverage:\")\n",
    "    print(\"-\" * 80)\n",
    "    if 'GW' in df_sample.columns:\n",
    "        gw_coverage = df_sample['GW'].value_counts().sort_index()\n",
    "        print(f\"Gameweeks present: {gw_coverage.index.min()} to {gw_coverage.index.max()}\")\n",
    "        print(f\"Total gameweeks: {len(gw_coverage)}\")\n",
    "        print(\"\\nPlayers per gameweek (sample):\")\n",
    "        print(gw_coverage.head(10))\n",
    "    elif 'round' in df_sample.columns:\n",
    "        round_coverage = df_sample['round'].value_counts().sort_index()\n",
    "        print(f\"Rounds present: {round_coverage.index.min()} to {round_coverage.index.max()}\")\n",
    "        print(f\"Total rounds: {len(round_coverage)}\")\n",
    "    \n",
    "    print(\"\\nPosition Distribution:\")\n",
    "    print(\"-\" * 80)\n",
    "    if 'position' in df_sample.columns:\n",
    "        pos_dist = df_sample['position'].value_counts()\n",
    "        print(pos_dist)\n",
    "    elif 'element_type' in df_sample.columns:\n",
    "        element_dist = df_sample['element_type'].value_counts()\n",
    "        print(\"Element Type Distribution (1=GK, 2=DEF, 3=MID, 4=FWD):\")\n",
    "        print(element_dist)\n",
    "    \n",
    "    print(\"\\nKey Performance Metrics - Sample Statistics:\")\n",
    "    print(\"-\" * 80)\n",
    "    key_metrics = ['total_points', 'minutes', 'goals_scored', 'assists', \n",
    "                   'clean_sheets', 'ict_index', 'influence', 'creativity', 'threat']\n",
    "    \n",
    "    available_metrics = [m for m in key_metrics if m in df_sample.columns]\n",
    "    \n",
    "    if available_metrics:\n",
    "        summary = df_sample[available_metrics].describe().T\n",
    "        summary['missing'] = df_sample[available_metrics].isna().sum()\n",
    "        summary['missing_pct'] = (summary['missing'] / len(df_sample)) * 100\n",
    "        print(summary[['count', 'mean', 'std', 'min', 'max', 'missing', 'missing_pct']])\n",
    "\n",
    "else:\n",
    "    print(\"No historical season data found for detailed profiling.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6e789",
   "metadata": {},
   "source": [
    "## SECTION 4: TEMPORAL COVERAGE SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20e4301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-22: 25,447 observations across 38 gameweeks (Range: 1-38)\n",
      "2022-23: 26,505 observations across 37 gameweeks (Range: 1-38)\n",
      "2023-24: 29,725 observations across 38 gameweeks (Range: 1-38)\n",
      "2024-25: 14,178 observations across 21 gameweeks (Range: 1-21)\n",
      "2025-26: 10,331 observations across 14 gameweeks (Range: 1-14)\n",
      "\n",
      "Total Temporal Coverage: 148 gameweeks\n",
      "Total Observations: 106,186\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "total_gameweeks = 0\n",
    "total_observations = 0\n",
    "\n",
    "for season in HISTORICAL_SEASONS + [CURRENT_SEASON]:\n",
    "    merged_file = RAW_DIR / f\"{season}_merged_gw.csv\"\n",
    "    \n",
    "    if not merged_file.exists():\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df_temp = pd.read_csv(merged_file)\n",
    "        \n",
    "        # Determine gameweek column\n",
    "        gw_col = 'GW' if 'GW' in df_temp.columns else 'round'\n",
    "        \n",
    "        if gw_col in df_temp.columns:\n",
    "            n_gw = df_temp[gw_col].nunique()\n",
    "            gw_range = f\"{df_temp[gw_col].min()}-{df_temp[gw_col].max()}\"\n",
    "        else:\n",
    "            n_gw = \"Unknown\"\n",
    "            gw_range = \"N/A\"\n",
    "        \n",
    "        n_obs = len(df_temp)\n",
    "        \n",
    "        print(f\"{season}: {n_obs:6,} observations across {n_gw} gameweeks (Range: {gw_range})\")\n",
    "        \n",
    "        if isinstance(n_gw, int):\n",
    "            total_gameweeks += n_gw\n",
    "        total_observations += n_obs\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{season}: Error - {str(e)}\")\n",
    "\n",
    "print(f\"\\nTotal Temporal Coverage: {total_gameweeks} gameweeks\")\n",
    "print(f\"Total Observations: {total_observations:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72425e86",
   "metadata": {},
   "source": [
    "## SECTION 5: DATA QUALITY ISSUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f2f07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical Fields Missing Value Analysis:\n",
      "--------------------------------------------------------------------------------\n",
      "total_points        :      0 missing ( 0.00%) ✓ OK\n",
      "minutes             :      0 missing ( 0.00%) ✓ OK\n",
      "element             :      0 missing ( 0.00%) ✓ OK\n",
      "opponent_team       :      0 missing ( 0.00%) ✓ OK\n",
      "was_home            :      0 missing ( 0.00%) ✓ OK\n",
      "\n",
      "Duplicate Records Check:\n",
      "--------------------------------------------------------------------------------\n",
      "Duplicate player-gameweek combinations: 2217\n",
      "\n",
      "Outlier Detection (Total Points):\n",
      "--------------------------------------------------------------------------------\n",
      "99th percentile: 12.0 points\n",
      "Observations above 99th percentile: 190 (0.75%)\n",
      "\n",
      "Top 10 extreme performances:\n",
      "                         name position  total_points  minutes  goals_scored  assists\n",
      "                  Mason Mount      MID            24       90             3        1\n",
      "                Mohamed Salah      MID            24       90             3        1\n",
      "    Gabriel Fernando de Jesus      FWD            24       90             4        1\n",
      "              Kevin De Bruyne      MID            24       90             4        0\n",
      "                  Reece James      DEF            21       90             2        0\n",
      "                Heung-Min Son      MID            21       77             3        0\n",
      "Bruno Miguel Borges Fernandes      MID            20       90             3        0\n",
      "              Roberto Firmino      FWD            20       90             3        1\n",
      "                Jack Harrison      MID            20       90             3        0\n",
      "                   Sadio Mané      MID            19       90             2        1\n",
      "\n",
      "================================================================================\n",
      "\n",
      "DATA AUDIT COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "if first_season:\n",
    "    df_quality = pd.read_csv(RAW_DIR / f\"{first_season}_merged_gw.csv\")\n",
    "    \n",
    "    print(\"Critical Fields Missing Value Analysis:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    critical_fields = ['total_points', 'minutes', 'element', 'opponent_team', 'was_home']\n",
    "    \n",
    "    for field in critical_fields:\n",
    "        if field in df_quality.columns:\n",
    "            n_missing = df_quality[field].isna().sum()\n",
    "            pct_missing = (n_missing / len(df_quality)) * 100\n",
    "            status = \"⚠ WARNING\" if pct_missing > 5 else \"✓ OK\"\n",
    "            print(f\"{field:20s}: {n_missing:6d} missing ({pct_missing:5.2f}%) {status}\")\n",
    "    \n",
    "    print(\"\\nDuplicate Records Check:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    if 'element' in df_quality.columns and 'GW' in df_quality.columns:\n",
    "        n_duplicates = df_quality.duplicated(subset=['element', 'GW']).sum()\n",
    "        print(f\"Duplicate player-gameweek combinations: {n_duplicates}\")\n",
    "    elif 'element' in df_quality.columns and 'round' in df_quality.columns:\n",
    "        n_duplicates = df_quality.duplicated(subset=['element', 'round']).sum()\n",
    "        print(f\"Duplicate player-round combinations: {n_duplicates}\")\n",
    "    \n",
    "    print(\"\\nOutlier Detection (Total Points):\")\n",
    "    print(\"-\" * 80)\n",
    "    if 'total_points' in df_quality.columns:\n",
    "        q99 = df_quality['total_points'].quantile(0.99)\n",
    "        n_extreme = (df_quality['total_points'] > q99).sum()\n",
    "        print(f\"99th percentile: {q99:.1f} points\")\n",
    "        print(f\"Observations above 99th percentile: {n_extreme} ({n_extreme/len(df_quality)*100:.2f}%)\")\n",
    "        \n",
    "        if n_extreme > 0:\n",
    "            print(\"\\nTop 10 extreme performances:\")\n",
    "            extreme_cols = ['name', 'position', 'total_points', 'minutes', 'goals_scored', 'assists']\n",
    "            available_extreme = [c for c in extreme_cols if c in df_quality.columns]\n",
    "            if available_extreme:\n",
    "                print(df_quality.nlargest(10, 'total_points')[available_extreme].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"DATA AUDIT COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
