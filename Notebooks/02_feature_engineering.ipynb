{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Production Feature Engineering Pipeline\n",
    "\n",
    "**Objective:** Transform raw FPL data into a high-dimensional feature space $X$ suitable for regression models (XGBoost/LightGBM).\n",
    "\n",
    "**Methodology:**\n",
    "1. **Temporal Features:** EWMA (Exponential Weighted Moving Average) and Rolling Means for [3, 6, 10] GWs.\n",
    "2. **Stability Metrics:** Coefficient of Variation (CV) for minutes (detecting rotation risk).\n",
    "3. **Contextual Features:** Opponent Defensive Strength & **Future Fixture Difficulty**.\n",
    "4. **Interaction Features:** Value Efficiency & Relative Form.\n",
    "5. **Target Engineering:** Cumulative points for $t+1, t+2, t+3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "BASE_DIR = Path.cwd().parent if 'Notebooks' in str(Path.cwd()) else Path.cwd()\n",
    "PROCESSED_DIR = BASE_DIR / \"data\" / \"processed\"\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 1. Data Ingestion\n",
    "Loading the unified preprocessed dataset. Ensure `src/preprocess.py` has been run recently to include `opponent_team_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(PROCESSED_DIR / \"fpl_unified_preprocessed.csv\")\n",
    "\n",
    "# Temporal Sort is NON-NEGOTIABLE for Time Series\n",
    "df['kickoff_time'] = pd.to_datetime(df['kickoff_time'])\n",
    "df = df.sort_values(['season', 'GW', 'element']).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded {len(df):,} rows.\")\n",
    "print(f\"Columns: {list(df.columns[:10])}...\")\n",
    "\n",
    "# Quick check for the patch\n",
    "if 'opponent_team_name' not in df.columns:\n",
    "    raise ValueError(\"CRITICAL: 'opponent_team_name' missing. Run src/preprocess.py first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal_features",
   "metadata": {},
   "source": [
    "## 2. Temporal Features (The Past)\n",
    "\n",
    "We implement two types of memory:\n",
    "1. **Rolling Mean:** Simple average. Good for baseline.\n",
    "2. **EWMA (Exponential Weighted Moving Average):** assigns higher weight to recent games. \n",
    "   $$y_t = \\alpha x_t + (1-\\alpha) y_{t-1}$$\n",
    "   where $\\alpha = 2/(span+1)$.\n",
    "\n",
    "**Windows:** `[3, 6, 10]` gameweeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_temporal_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    metrics = ['total_points', 'minutes', 'ict_index', 'influence', 'creativity', 'threat', 'goals_scored', 'assists']\n",
    "    windows = [3, 6, 10]\n",
    "    \n",
    "    # 1. Lags (What happened last game?)\n",
    "    print(\"Generating Lag Features...\")\n",
    "    for m in ['total_points', 'minutes']:\n",
    "        df[f'{m}_lag_1'] = df.groupby('element')[m].shift(1)\n",
    "\n",
    "    # 2. Rolling & EWMA\n",
    "    print(f\"Generating Rolling & EWMA Features for windows {windows}...\")\n",
    "    for window in windows:\n",
    "        for m in metrics:\n",
    "            # Simple Rolling Mean\n",
    "            df[f'{m}_roll_{window}'] = df.groupby('element')[m].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            \n",
    "            # EWMA (More sensitive to form)\n",
    "            df[f'{m}_ewma_{window}'] = df.groupby('element')[m].transform(lambda x: x.ewm(span=window, adjust=False).mean())\n",
    "\n",
    "    # 3. Stability Metric (Coefficient of Variation for Minutes)\n",
    "    # Low CV = \"Nailed\" (Consistent minutes). High CV = Rotation Risk.\n",
    "    print(\"Generating Stability Metrics...\")\n",
    "    df['minutes_std_5'] = df.groupby('element')['minutes'].transform(lambda x: x.rolling(5, min_periods=1).std())\n",
    "    df['minutes_mean_5'] = df.groupby('element')['minutes'].transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    "    df['minutes_cv_5'] = df['minutes_std_5'] / (df['minutes_mean_5'] + 1e-6) # Avoid div/0\n",
    "\n",
    "    return df\n",
    "\n",
    "df = engineer_temporal_features(df)\n",
    "print(\"Temporal Engineering Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "context_features",
   "metadata": {},
   "source": [
    "## 3. Contextual Features (The Future)\n",
    "\n",
    "**The Problem:** Standard models only look at *past* opponents. \n",
    "**The Solution:** We must inject knowledge of the *upcoming* schedule.\n",
    "\n",
    "1. Calculate **Team Defensive Strength** (Rolling 5 GW goals conceded).\n",
    "2. Map this strength to the player's **Next 3 Opponents**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "context_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Calculate Team Defensive Strength\n",
    "def calculate_team_defense(df):\n",
    "    # Lower is better (fewer goals conceded)\n",
    "    team_stats = df.groupby(['season', 'GW', 'team'])['goals_conceded'].mean().reset_index()\n",
    "    team_stats = team_stats.sort_values(['season', 'team', 'GW'])\n",
    "    team_stats['def_strength_5'] = team_stats.groupby('team')['goals_conceded'].transform(lambda x: x.rolling(5, min_periods=1).mean())\n",
    "    return team_stats[['season', 'GW', 'team', 'def_strength_5']]\n",
    "\n",
    "team_defense = calculate_team_defense(df)\n",
    "\n",
    "# B. Merge Defensive Strength for CURRENT Match (The Opponent)\n",
    "# We match (Player's Opponent Name) -> (Team Defense Table)\n",
    "df = df.merge(\n",
    "    team_defense,\n",
    "    left_on=['season', 'GW', 'opponent_team_name'],\n",
    "    right_on=['season', 'GW', 'team'],\n",
    "    how='left',\n",
    "    suffixes=('', '_opp_lookup')\n",
    ")\n",
    "df.rename(columns={'def_strength_5': 'opponent_strength_current'}, inplace=True)\n",
    "df.drop(columns=['team_opp_lookup'], inplace=True)\n",
    "\n",
    "# Fill NaNs (Early gameweeks or missing map) with League Average\n",
    "mean_def = df['opponent_strength_current'].mean()\n",
    "df['opponent_strength_current'] = df['opponent_strength_current'].fillna(mean_def)\n",
    "\n",
    "print(\"Opponent Strength Calculated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future_difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. Look-Ahead: Calculate Upcoming Fixture Difficulty\n",
    "# Logic: Shift the 'opponent_strength_current' column BACKWARDS for each player.\n",
    "# Shift(-1) is the NEXT game's opponent strength.\n",
    "\n",
    "print(\"Calculating Future Fixture Difficulty (Next 3 GWs)...\")\n",
    "\n",
    "df = df.sort_values(['season', 'element', 'GW']) # Ensure sorted by player time\n",
    "\n",
    "df['next_opp_strength_1'] = df.groupby('element')['opponent_strength_current'].shift(-1)\n",
    "df['next_opp_strength_2'] = df.groupby('element')['opponent_strength_current'].shift(-2)\n",
    "df['next_opp_strength_3'] = df.groupby('element')['opponent_strength_current'].shift(-3)\n",
    "\n",
    "# Feature: Average difficulty of next 3 games\n",
    "df['upcoming_difficulty_3gw'] = df[['next_opp_strength_1', 'next_opp_strength_2', 'next_opp_strength_3']].mean(axis=1)\n",
    "\n",
    "# Note: The last 3 GWs of a season will have NaNs. This is expected.\n",
    "print(df[['name', 'GW', 'opponent_team_name', 'opponent_strength_current', 'upcoming_difficulty_3gw']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interaction_features",
   "metadata": {},
   "source": [
    "## 4. Interaction Features\n",
    "\n",
    "Combining raw features to capture efficiency and relative performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interaction_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Value Efficiency (Points per Million)\n",
    "df['value_efficiency'] = df['total_points_ewma_6'] / (df['value'] + 0.1)\n",
    "\n",
    "# 2. Home/Away Bias\n",
    "# Ratio of Home Points vs Away Points (Rolling)\n",
    "# If > 1, Player prefers Home. If < 1, Player prefers Away.\n",
    "home_pts = df[df['was_home']==True].groupby('element')['total_points'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "away_pts = df[df['was_home']==False].groupby('element')['total_points'].rolling(10, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# This is complex to merge back due to different indices (home vs away rows).\n",
    "# Simplified Approach: Interaction Term\n",
    "df['home_advantage_feature'] = df['total_points_ewma_10'] * df['was_home'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "target_gen",
   "metadata": {},
   "source": [
    "## 5. Target Generation\n",
    "\n",
    "We predict the sum of points over the next 3 Gameweeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "target_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 3\n",
    "df['target_points_next_3'] = df.groupby('element')['total_points'].transform(lambda x: x.rolling(horizon).sum().shift(-horizon))\n",
    "\n",
    "# Validate\n",
    "print(\"Target Distribution:\")\n",
    "print(df['target_points_next_3'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleanup",
   "metadata": {},
   "source": [
    "## 6. The Clean & Save\n",
    "Remove artifacts and save the Feature Matrix $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where Target is NaN (End of seasons)\n",
    "df_model = df.dropna(subset=['target_points_next_3'])\n",
    "\n",
    "# Drop highly collinear / leakage columns\n",
    "drop_cols = ['match_score', 'own_goals', 'penalties_missed', 'penalties_saved', 'saves', 'bonus', 'bps'] \n",
    "df_model = df_model.drop(columns=[c for c in drop_cols if c in df_model.columns])\n",
    "\n",
    "print(f\"Final Feature Matrix Shape: {df_model.shape}\")\n",
    "\n",
    "output_path = PROCESSED_DIR / \"fpl_features_production.csv\"\n",
    "df_model.to_csv(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
